{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722855bb-c337-40ea-aabb-e6b55ff162e5",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25efa8-1109-4137-b500-a6a4bb5f9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, wait, ALL_COMPLETED, as_completed\n",
    "from datetime import datetime, timedelta\n",
    "from multiprocessing import Process, Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import h5py\n",
    "# import Bio\n",
    "# from Bio import motifs\n",
    "# import pysam\n",
    "import pyranges\n",
    "import pybedtools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy\n",
    "from scipy import io\n",
    "import scanpy as sc\n",
    "from sklearn.cluster import KMeans\n",
    "# from adjustText import adjust_text\n",
    "# import episcanpy\n",
    "import ruamel.yaml\n",
    "yaml = ruamel.yaml.YAML(typ=\"safe\")\n",
    "yaml.default_flow_style = False\n",
    "from matplotlib_venn import venn3, venn2, venn3_unweighted, venn2_unweighted\n",
    "\n",
    "import SCRIP\n",
    "from SCRIP.utilities import utils\n",
    "from SCRIP.utilities.utils import print_log, safe_makedirs, excute_info, read_pickle, read_SingleCellExperiment_rds, store_to_pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "# warnings.simplefilter(action='ignore', category=subprocess.)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': [8.0, 8.0],\n",
    "    'font.size' : 15,\n",
    "    'font.family': 'Arial',\n",
    "    'font.style' : 'normal',\n",
    "    'font.weight':'normal',\n",
    "    'figure.titleweight': 'normal',\n",
    "    'axes.labelsize': 14 ,\n",
    "    'axes.titleweight': 'normal',\n",
    "    'axes.labelweight': 'normal',\n",
    "    'axes.spines.right': False,\n",
    "    'axes.spines.top': False,\n",
    "})\n",
    "\n",
    "N = 256\n",
    "vals = np.ones((N, 4))\n",
    "vals[:, 0] = np.linspace(220/256, 34/256, N)\n",
    "vals[:, 1] = np.linspace(220/256, 7/256, N)\n",
    "vals[:, 2] = np.linspace(220/256, 141/256, N)\n",
    "regulation_cmp = mpl.colors.ListedColormap(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123d2a8-aa03-4508-b878-38a58855c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c47aeb-e985-4fb8-b701-8290742d778c",
   "metadata": {},
   "source": [
    "# Function Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1337793-0f89-4721-86d8-7b3a1726f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def find_nearest_cells(q_point, tree, n_neighbor):\n",
    "    _, ind = tree.query(q_point, k=n_neighbor+1)\n",
    "    return ind[0][1:]\n",
    "\n",
    "def cal_neighbor_cell_peak_mat(sub_mat, input_mat, tree, pc_table, impute_n, start_idx, i):\n",
    "    end_index = start_idx + sub_mat.shape[0]\n",
    "    k = 0\n",
    "    for idx in range(start_idx, end_index):\n",
    "        nearest_bc_idx = find_nearest_cells(np.reshape(pc_table[idx,:], (1,-1)), tree, n_neighbor=impute_n)\n",
    "#         scipy.sparse.csr_matrix(input_mat[nearest_bc_idx,:].sum(0))\n",
    "        sub_mat[k,:] = input_mat[nearest_bc_idx,:].sum(0)\n",
    "        k += 1\n",
    "    return sub_mat\n",
    "\n",
    "def cal_neighbor_cell_peak_mat_batch(input_mat, impute_n=5, KD_leafsize=80, nPC = 50, n_cores=8):\n",
    "    '''\n",
    "    input_mat:\n",
    "    a csr sparse matrix, which can be get by adata.X\n",
    "    \n",
    "    '''\n",
    "    print_log(\"Building KD tree...\")\n",
    "    pc_table = sc.tl.pca(input_mat, n_comps=50, svd_solver='arpack')\n",
    "    tree = BallTree(pc_table, KD_leafsize)\n",
    "    print_log(\"Calculating neighbors, divide into {n} chunks...\".format(n=n_cores))\n",
    "    cell_number = input_mat.shape[0]\n",
    "    index_split = [i for i in range(0,cell_number,int(cell_number/n_cores))] + [cell_number]\n",
    "#     input_table_split = np.array_split(input_mat_dense, n_cores)\n",
    "    input_mat_lil = input_mat.tolil()\n",
    "    input_mat_split = [input_mat_lil[index_split[i]:index_split[i+1],:] for i in range(index_split.__len__()-1)]\n",
    "    args = [[sub_mat, input_mat, tree, pc_table, impute_n, index_split[i], i] for (i, sub_mat) in enumerate(input_mat_split)]\n",
    "#     print(args)\n",
    "    with Pool(n_cores) as p:\n",
    "        result = p.starmap(cal_neighbor_cell_peak_mat, args)\n",
    "    cell_peak_csr = scipy.sparse.vstack(result).tocsr()\n",
    "    print_log('Finished!')\n",
    "    return cell_peak_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b7970-1bf6-4530-85f4-38f24b62b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_peak_list(cells, input_mat, peak_confidence=1):\n",
    "    cell_above_cutoff_index = sc.pp.filter_genes(\n",
    "        input_mat[cells, :], min_cells=peak_confidence, inplace=False)[0]\n",
    "    peaks = input_mat.var_names[cell_above_cutoff_index].to_list()\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def generate_beds(file_path, cells, input_mat, peak_confidence=1):\n",
    "    peaks = generate_peak_list(cells, input_mat, peak_confidence)\n",
    "    cell_barcode = os.path.basename(file_path)[:-4]  # remove .bed\n",
    "    if peaks.__len__() == 0:\n",
    "        print_log('Warning: No peaks in {bed_path}, skip generation'.format(bed_path=file_path[:-4]))\n",
    "    else:\n",
    "        peaks = pd.DataFrame([p.rsplit(\"_\", 2) for p in peaks])\n",
    "        peaks.to_csv(file_path, sep=\"\\t\", header=None, index=None)\n",
    "        cmd = 'sort --buffer-size 2G -k1,1 -k2,2n -k3,3n {bed_path} | bgzip -c > {bed_path}.gz\\n'.format(bed_path=file_path)\n",
    "        cmd += 'rm {bed_path}'.format(bed_path=file_path)\n",
    "        subprocess.run(cmd, shell=True, check=True)\n",
    "    return [cell_barcode, peaks.__len__()]\n",
    "\n",
    "\n",
    "def generate_beds_by_matrix(cell_feature_adata, beds_path, peaks_number_path, n_cores):\n",
    "    safe_makedirs(beds_path)\n",
    "    # total_cnt = adata.obs.index.__len__()\n",
    "    executor = ThreadPoolExecutor(max_workers=n_cores)\n",
    "    all_task = []\n",
    "    for cell in cell_feature_adata.obs.index:\n",
    "        # neighbor_cells = find_nearest_cells(cell, coor_table, n_neighbor, step)\n",
    "        # map_dict[cell] = neighbor_cells\n",
    "        all_task.append(executor.submit(generate_beds, beds_path + \"/\" + str(cell) + \".bed\", cell, cell_feature_adata))\n",
    "    wait(all_task, return_when=ALL_COMPLETED)\n",
    "    pd.DataFrame([_.result() for _ in as_completed(all_task)]).to_csv(peaks_number_path, header=None, index=None, sep='\\t')\n",
    "    return\n",
    "\n",
    "\n",
    "def search_ref_factor(bed_path, result_path, index_path, factor):\n",
    "    cmd = f'giggle search -i \"{index_path}\" -q \"{bed_path}\" -s -f {factor}_ > \"{result_path}\"\\n'\n",
    "    # cmd = f'igd search {index_path}/ref.igd -q {bed_path} | head -n -1 | cut -f 2,3,4 > {result_path}'\n",
    "    # cmd = f'seqpare \"{index_path}/*.bed.gz\" \"{bed_path}\" -m 1 -o {result_path}\\n'\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "def search_ref_factor_batch(bed_folder, result_folder, index_path, factor, n_cores=8, tp=''):\n",
    "    print_log(f'Start searching beds from {tp} index ...')\n",
    "    safe_makedirs(result_folder)\n",
    "    beds = os.listdir(bed_folder)\n",
    "    args = []\n",
    "    for bed in beds:\n",
    "        barcodes = bed[:-7]  # remove suffix '.bed.gz'\n",
    "        args.append((os.path.join(bed_folder, bed),\n",
    "                     os.path.join(result_folder, barcodes + '.txt'),\n",
    "                     index_path,\n",
    "                     factor))\n",
    "    with Pool(n_cores) as p:\n",
    "        p.starmap(search_ref_factor, args)\n",
    "    print_log(f'Finished searching beds from {tp} index ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05f185-812d-487f-85b6-362f53105114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_ref(bed_path, result_path, index_path):\n",
    "    cmd = f'giggle search -i \"{index_path}\" -q \"{bed_path}\" -s > \"{result_path}\"\\n'\n",
    "    # cmd = f'igd search {index_path}/ref.igd -q {bed_path} | head -n -1 | cut -f 2,3,4 > {result_path}'\n",
    "    # cmd = f'seqpare \"{index_path}/*.bed.gz\" \"{bed_path}\" -m 1 -o {result_path}\\n'\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "def search_ref_batch(bed_folder, result_folder, index_path, n_cores=8, tp=''):\n",
    "    print_log(f'Start searching beds from {tp} index ...')\n",
    "    safe_makedirs(result_folder)\n",
    "    beds = os.listdir(bed_folder)\n",
    "    args = []\n",
    "    for bed in beds:\n",
    "        barcodes = bed[:-7]  # remove suffix '.bed.gz'\n",
    "        args.append((os.path.join(bed_folder, bed),\n",
    "                     os.path.join(result_folder, barcodes + '.txt'),\n",
    "                     index_path))\n",
    "    with Pool(n_cores) as p:\n",
    "        p.starmap(search_ref, args)\n",
    "    print_log(f'Finished searching beds from {tp} index ...')\n",
    "\n",
    "\n",
    "def read_search_result(files):\n",
    "    for i in range(len(files)):\n",
    "        result_name = os.path.basename(files[i])\n",
    "        cell_bc = result_name[:-4]  # remove suffix '.txt'\n",
    "        dtframe = pd.read_csv(files[i], sep=\"\\t\", index_col=0, comment='#', header=None)\n",
    "        read_col = 2  # 1 file_size 2 overlaps 3 odds_ratio 4 fishers_two_tail 5 fishers_left_tail 6 fishers_right_tail 7 combo_score\n",
    "        if i == 0:\n",
    "            dtframe = dtframe.loc[:, [read_col]].copy()\n",
    "            dataset_cell_score_df = dtframe.rename(columns={read_col: cell_bc}).copy()\n",
    "        else:\n",
    "            dataset_cell_score_df[cell_bc] = dtframe.loc[:, read_col]\n",
    "    dataset_cell_score_df.index = [i.rsplit('/', 1)[0][:-7] for i in dataset_cell_score_df.index]  # remove suffix '.bed.gz'\n",
    "    return dataset_cell_score_df\n",
    "\n",
    "\n",
    "def read_search_result_batch(path, n_cores=8, tp=''):\n",
    "    print_log(f\"Reading searching results, using {n_cores} cores...\")\n",
    "    file_list = os.listdir(path)\n",
    "    result_split = np.array_split(file_list, n_cores)\n",
    "    args = [[[os.path.join(path, j) for j in list_chunk]] for list_chunk in result_split]\n",
    "    with Pool(n_cores) as p:\n",
    "        result = p.starmap(read_search_result, args)\n",
    "    dataset_cell_score_df = pd.concat([i for i in result], axis=1)\n",
    "    print_log(f\"Finished reading {tp} index search result!\")\n",
    "    return dataset_cell_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3fda5-dfd0-4250-b3b8-806af44e851d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cbcf5-1d1b-4738-a877-25216e41256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@excute_info('Getting the best reference for each cell.')\n",
    "def get_factor_source(table):\n",
    "    ret_table = table.copy()\n",
    "    # map factor by id \"_\"\n",
    "    factor_index_list = []\n",
    "    for i in ret_table.index:\n",
    "        factor_name = i.split(\"_\")\n",
    "        factor_index_list.append(factor_name[0])\n",
    "    ret_table.loc[:, \"Factor\"] = factor_index_list\n",
    "    max_index = ret_table.groupby(\"Factor\").idxmax()\n",
    "    return max_index\n",
    "\n",
    "\n",
    "def cal_score(dataset_overlap_df, peaks_number):\n",
    "    '''\n",
    "    nql: normalize query peak length\n",
    "    dm: divide the mean\n",
    "    '''\n",
    "    dataset_cell_percent = (dataset_overlap_df.T/peaks_number.loc[dataset_overlap_df.index, 1]).T\n",
    "    dataset_cell_percent_scale = (dataset_cell_percent/dataset_cell_percent.sum())*1e4\n",
    "    dataset_cell_percent_scale_dm = (dataset_cell_percent_scale.T/dataset_cell_percent_scale.mean(1)).T\n",
    "    return dataset_cell_percent_scale_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d79ee-d64d-4de7-8d1b-d1c38fcae1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_mtx(data, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    pd.DataFrame(data.var.index).to_csv(os.path.join(path, \"genes.tsv\" ), sep = \"\\t\", index=False, header=False)\n",
    "    pd.DataFrame(data.obs.index).to_csv(os.path.join(path, \"barcodes.tsv\"), sep = \"\\t\", index=False, header=False)\n",
    "    data.obs.to_csv(os.path.join(path, \"metadata.tsv\"), sep = \"\\t\", index=False, header=False)\n",
    "    io.mmwrite(os.path.join(path, \"matrix.mtx\"), data.X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee631614-ff84-49ef-8147-1817fec23705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneInfoSimple(gene_bed):\n",
    "    genes_info = []\n",
    "    genes_list = []\n",
    "    fhd = open(gene_bed, 'rt')\n",
    "    fhd.readline() # skip the first line. In our current gene txt file, there is no '#' in the first line. We need to, perhaps, use the 'ExtractGeneInfo' function.\n",
    "    for line in fhd:\n",
    "        line = line.strip().split('\\t')\n",
    "        if not line[0].startswith('#'):\n",
    "            if line[3] == \"+\":\n",
    "                genes_info.append((line[2].replace('chr',''), int(line[4]), 1, \"%s@%s@%s\" % (line[12], line[2], line[4])))\n",
    "            else:\n",
    "                genes_info.append((line[2].replace('chr',''), int(line[5]), 1, \"%s@%s@%s\" % (line[12], line[2], line[5])))\n",
    "                # gene_info [chrom, tss, 1, gene_unique]\n",
    "    fhd.close()\n",
    "    genes_info = list(set(genes_info))\n",
    "    for igene in range(len(genes_info)):\n",
    "        tmp_gene = list(genes_info[igene])\n",
    "        genes_list.append(tmp_gene[3])\n",
    "        tmp_gene[3] = igene\n",
    "        genes_info[igene] = tmp_gene\n",
    "    return genes_info, genes_list\n",
    "\n",
    "def RP_Simple(peaks_info, genes_info, decay):\n",
    "    \"\"\"Multiple processing function to calculate regulation potential.\"\"\"\n",
    "\n",
    "    Sg = lambda x: 2**(-x)\n",
    "    gene_distance = 15 * decay\n",
    "    genes_peaks_score_array = scipy.sparse.dok_matrix((len(genes_info), len(peaks_info)), dtype=np.float64)\n",
    "\n",
    "    w = genes_info + peaks_info\n",
    "\n",
    "    A = {}\n",
    "\n",
    "    w.sort()\n",
    "    for elem in w:\n",
    "        if elem[2] == 1:\n",
    "            A[elem[-1]] = [elem[0], elem[1]]\n",
    "        else:\n",
    "            dlist = []\n",
    "            for gene_name in list(A.keys()):\n",
    "                g = A[gene_name]\n",
    "                tmp_distance = abs(elem[1] - g[1])\n",
    "                if (g[0] != elem[0]) or (tmp_distance > gene_distance):\n",
    "                    dlist.append(gene_name)\n",
    "                else:\n",
    "                    genes_peaks_score_array[gene_name, elem[-1]] = Sg(tmp_distance / decay)\n",
    "            for gene_name in dlist:\n",
    "                del A[gene_name]\n",
    "\n",
    "    w.reverse()\n",
    "    for elem in w:\n",
    "        if elem[2] == 1:\n",
    "            A[elem[-1]] = [elem[0], elem[1]]\n",
    "        else:\n",
    "            dlist = []\n",
    "            for gene_name in list(A.keys()):\n",
    "                g = A[gene_name]\n",
    "                tmp_distance = abs(g[1] - elem[1])\n",
    "                if (g[0] != elem[0]) or (tmp_distance > gene_distance):\n",
    "                    dlist.append(gene_name)\n",
    "                else:\n",
    "                    genes_peaks_score_array[gene_name, elem[-1]] = Sg(tmp_distance / decay)\n",
    "            for gene_name in dlist:\n",
    "                del A[gene_name]\n",
    "\n",
    "    return genes_peaks_score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82f974-d451-49bb-83d6-bf965d1939d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(input_mat, impute_n=5, KD_leafsize=80, nPC = 50, path='SCRIPT/enhancement/', binarize=True, n_cores=8):\n",
    "    '''\n",
    "    input_mat:\n",
    "    a csr sparse matrix\n",
    "    \n",
    "    '''\n",
    "    safe_makedirs(path)\n",
    "    imputed_csr = cal_neighbor_cell_peak_mat_batch(input_mat, impute_n=impute_n, KD_leafsize=KD_leafsize, nPC = nPC, n_cores=n_cores)\n",
    "    if binarize == True:\n",
    "        imputed_csr[imputed_csr>1] = 1\n",
    "    utils.store_to_pickle(imputed_csr, path + 'imputed.csr.pk')\n",
    "    return imputed_csr\n",
    "\n",
    "\n",
    "def impute(input_mat_adata, impute_factor, ref_path, bed_check=True, search_check=True, path='SCRIPT/imputation/', write_mtx=True, ref_baseline=500, remove_others_source=False, n_cores=8):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    safe_makedirs(path)\n",
    "    print(input_mat_adata.X.shape)\n",
    "    if bed_check == True:\n",
    "        if not os.path.exists(f'{path}/imputed_beds/'):\n",
    "            print_log('Generating beds...')\n",
    "            generate_beds_by_matrix(input_mat_adata, path + '/imputed_beds/', path + '/imputed_beds_peaks_number.txt', n_cores)\n",
    "        else:\n",
    "            print_log('Skip generate beds...')\n",
    "    else:\n",
    "        print_log('Generating beds...')\n",
    "        generate_beds_by_matrix(input_mat_adata, path + '/imputed_beds/', path + '/imputed_beds_peaks_number.txt', n_cores)\n",
    "    \n",
    "    if search_check == True:\n",
    "        if not os.path.exists(path + '/imputed_results_%s/' % impute_factor):\n",
    "            search_ref_factor_batch(path + '/imputed_beds/', path + '/imputed_results_%s/' % impute_factor, ref_path, impute_factor, n_cores)\n",
    "        else:\n",
    "            print_log('Skip searching beds...')\n",
    "    else:\n",
    "        search_ref_factor_batch(path + '/imputed_beds/', path + '/imputed_results_%s/' % impute_factor, ref_path, impute_factor, n_cores)\n",
    "    \n",
    "    print_log('Calculating score...')\n",
    "    factor_enrich = read_search_result_batch(path + '/imputed_results_%s/' % impute_factor, n_cores)\n",
    "    \n",
    "    peaks_length = pd.read_csv(os.path.join(ref_path, 'peaks_number.txt'), sep='\\t', header=None, index_col=0)\n",
    "    peaks_length_factor = peaks_length.loc[[i for i in peaks_length.index if i.startswith(impute_factor)], :].copy()\n",
    "    factor_score = cal_score(factor_enrich, peaks_length_factor)\n",
    "\n",
    "    factor_source = get_factor_source(factor_score)\n",
    "    store_to_pickle(factor_source, path + '%s_dataset_source.pk' % impute_factor)\n",
    "\n",
    "    chip_bed_list = [pybedtools.BedTool(os.path.join(ref_path, 'raw_beds', i + '.bed.gz')) for i in factor_source.iloc[0,:].unique()]\n",
    "    chip_bed = chip_bed_list[0].cat(*chip_bed_list[1:])\n",
    "    data_bed = pybedtools.BedTool('\\n'.join(['\\t'.join(p.rsplit('_', maxsplit=2)) for p in input_mat_adata.var_names]), from_string=True)\n",
    "    intersect_bed = data_bed.intersect(chip_bed, u=True)\n",
    "    imputed_chip_peak = str(intersect_bed).replace('\\t','_').split('\\n')[0:-1]\n",
    "    \n",
    "    chip_cell_peak = input_mat_adata[:,imputed_chip_peak].copy()\n",
    "    chip_cell_peak_df = chip_cell_peak.to_df()\n",
    "    if remove_others_source == True:\n",
    "        for i in factor_source.iloc[0,:].unique():\n",
    "            cellbc = factor_source.columns[factor_source.iloc[0,:] == i]\n",
    "            tmp_dataset_bed = pybedtools.BedTool(os.path.join(ref_path, i + '.bed.gz'))\n",
    "            exclude_chip_peak = str(intersect_bed.intersect(tmp_dataset_bed, v=True)).replace('\\t','_').split('\\n')[0:-1]\n",
    "            chip_cell_peak_df.loc[cellbc,exclude_chip_peak] = 0\n",
    "    chip_cell_peak = sc.AnnData(chip_cell_peak_df)\n",
    "    chip_cell_peak.X = scipy.sparse.csr.csr_matrix(chip_cell_peak.X)\n",
    "    print_log('Writing results...')\n",
    "    if write_mtx == True:\n",
    "        write_to_mtx(chip_cell_peak, path + '/imputed_%s_mtx/' % impute_factor)\n",
    "    print_log('Finished!')\n",
    "    return chip_cell_peak, factor_score\n",
    "\n",
    "def count_to_gene_by_RP(input_adata, decay=100000, refgene_path='/fs/home/dongxin/Files/GRCm38_refgenes.txt'):\n",
    "    cells_list = input_adata.obs.index.tolist()\n",
    "    peaks_list = input_adata.var.index.tolist()\n",
    "\n",
    "    genes_info, genes_list= geneInfoSimple(refgene_path)\n",
    "\n",
    "    peaks_info = []\n",
    "    for ipeak, peak in enumerate(peaks_list):\n",
    "        peaks_tmp = peak.rsplit(\"_\", maxsplit=2)\n",
    "        peaks_info.append([peaks_tmp[0][3:], (int(peaks_tmp[1]) + int(peaks_tmp[2])) / 2.0, 0, ipeak])\n",
    "\n",
    "    genes_peaks_score_dok = RP_Simple(peaks_info, genes_info, decay)\n",
    "\n",
    "    genes_peaks_score_csr = genes_peaks_score_dok.tocsr()\n",
    "    genes_cells_score_csr = genes_peaks_score_csr.dot(chip_cell_peak.X.T)\n",
    "\n",
    "    score_cells_dict = {}\n",
    "    score_cells_sum_dict = {}\n",
    "\n",
    "    for igene, gene in enumerate(genes_list):\n",
    "        score_cells_dict[gene] = igene\n",
    "        score_cells_sum_dict[gene] = genes_cells_score_csr[igene, :].sum()\n",
    "\n",
    "    score_cells_dict_dedup = {}\n",
    "    score_cells_dict_max = {}\n",
    "    genes = list(set([i.split(\"@\")[0] for i in genes_list]))\n",
    "    for gene in genes:\n",
    "        score_cells_dict_max[gene] = float(\"-inf\")\n",
    "\n",
    "    for gene in genes_list:\n",
    "        symbol = gene.split(\"@\")[0]\n",
    "        if score_cells_sum_dict[gene] > score_cells_dict_max[symbol]:\n",
    "            score_cells_dict_dedup[symbol] = score_cells_dict[gene]\n",
    "            score_cells_dict_max[symbol] = score_cells_sum_dict[gene]\n",
    "    gene_symbol = sorted(score_cells_dict_dedup.keys())\n",
    "    matrix_row = []\n",
    "    for gene in gene_symbol:\n",
    "        matrix_row.append(score_cells_dict_dedup[gene])\n",
    "\n",
    "    score_cells_matrix = genes_cells_score_csr[matrix_row, :]\n",
    "\n",
    "    RP_adata = ad.AnnData(score_cells_matrix.T, obs=pd.DataFrame(index=cells_list.tolist()), var =pd.DataFrame(index=gene_symbol))\n",
    "    return RP_adata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07b747-1b51-47fb-8fe1-b51c91666ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac = read_SingleCellExperiment_rds('example/PBMC/data/PBMC_ATAC_500bin/analysis/PBMC_TBMono_500bin.rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9b3e2-712c-478d-8d89-a23840be01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac.var.index = [i.replace('-', '_') for i in atac.var.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462ab64-5d60-48ff-b3ba-37b88bb02ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_factor = 'H3K27ac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b572708-c732-412f-8817-02015ff3480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac.obs['nFeature_ATAC'] = atac.obs['nFeature_ATAC'].astype(int)\n",
    "atac.obs['nCount_ATAC'] = atac.obs['nCount_ATAC'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c851109-b0ae-48f1-9797-c4c0b5167292",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac.write_h5ad('example/PBMC/data/PBMC_ATAC_500bin/analysis/PBMC_TBMono_500bin.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767ea86-fb13-40c1-a0cc-e82437cbf5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac = ad.read_h5ad('example/PBMC/data/PBMC_ATAC_500bin/analysis/PBMC_TBMono_500bin.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9386d7-4f83-4a3a-bac1-2f9940878c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_cell_peak_H3K27ac, factor_score = impute(atac, 'H3K27ac', '/fs/home/dongxin/Projects/SCRIPT/indices/human/hm_chip_qc_5fold_giggle/', \n",
    "                                              bed_check=True, search_check=True, path='example/histone/peak_base/cuttagpro/SCRIPT_PBMC/imputationPBMC1022/', \n",
    "                                              write_mtx=True, ref_baseline=500, remove_others_source=False, n_cores=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058429b-dfe1-4d69-9d77-e5c9db8264ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(chip_cell_peak_H3K27ac, min_cells=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8530e8-b9a1-4b01-a56b-f866b389eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pickle('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/SCRIPT_1114_remove_others/imputation/H3K27ac_dataset_source.pk').iloc[0,:].value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f0b1aa-9d32-4ba8-bcfc-2e7a1f2fdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_pickle('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/SCRIPT_1114/imputation/H3K4me3_dataset_source.pk').iloc[0,:].value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a2425b-0aba-4ced-8d21-cbd60ee6c6bc",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d2276-a681-4c56-a231-2bd79fd66a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_t_target = pd.read_csv('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/62350_gene_score_5fold_T.txt', comment = '#', sep='\\t', header = None)\n",
    "bulk_mono_target = pd.read_csv('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/34935_gene_score_5fold_Mono.txt', comment = '#', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef087842-db97-48d0-abc8-e636adb7931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_t_target_list = bulk_t_target[6].unique()\n",
    "bulk_mono_target_list = bulk_mono_target[6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd20126-39f0-48c1-bfa2-15588f60dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_t_target_rp = bulk_t_target.groupby(6).max()[4]\n",
    "bulk_mono_target_rp = bulk_mono_target.groupby(6).max()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67465e2d-0a22-42ff-a2cd-a780f0ad036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_RP = sc.read_h5ad('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/SCRIPT_1114_remove_others/imputation/H3K27ac_RP.h5ad').to_df().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e92db5-c2b9-4a64-8ee1-61af44deb847",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_RP.columns = [i.split('-')[0] for i in impute_RP.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea4f0b-d1c7-4f7a-8732-4429d178a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pd.read_csv('example/PBMC/barcode_key.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ad49f-c424-4d19-9c39-31cee0e29893",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys.index = keys['ATAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77968f6f-a279-41c3-9b6e-57579a3f3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_metadata = pd.read_csv('example/PBMC/analysis/metadata.txt', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3ee87-c9c3-4b59-9ab4-6162c961da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_rp = sc.read_h5ad('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/H3K27ac_RP.h5ad').to_df().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209507b-6cd4-4bbd-8ea0-d284bdf4be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "atac_rp.columns = [i.split('-')[0] for i in atac_rp.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8114d98d-1215-4cab-9acf-067694c96f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_RP = pd.read_csv('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/peak_base/cuttagpro/SCRIPT_PBMC/real_RP.txt', sep='\\t')\n",
    "# store_to_pickle(real_RP, '/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/peak_base/cuttagpro/SCRIPT_PBMC/real_RP.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e24587-7974-44e8-975a-60644bc75a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_RP = read_pickle('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/peak_base/cuttagpro/SCRIPT_PBMC/real_RP.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33564ef4-d3c4-440c-b9dc-15d82b516af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_matadata = pd.read_csv('example/histone/peak_base/cuttagpro/SCRIPT_PBMC/real_meta_data.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb7be69-3c2e-4bb1-ae52-0d198118d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_metadata.loc['CGTACTTCAAGCGAAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fbe38-6d07-470e-9526-f0d701a4e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meta['CellType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7ecb3-4b1c-4961-b347-eb98c264aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_meta = pd.read_csv('example/PBMC/pbmc_meta.txt', sep='\\t', index_col=0)\n",
    "keys.index = keys['RNA']\n",
    "tmp_meta.index = [keys.loc[i,'ATAC'] for i in tmp_meta.index]\n",
    "keys.index = keys['ATAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349208a6-dfc9-4a25-974b-9f8fca0a5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RP correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c1793d-cb70-46e2-9c17-407c451432cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_ovlp_target = set(bulk_t_target_rp.index).intersection(impute_t_rp.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47fc12-524a-44f6-b2ad-16169c6b6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_t_bc = tmp_meta.index[(tmp_meta['CellType'] == 'naive_CD4_T_cells') | (tmp_meta['CellType'] == 'memory_CD4_T_cells') | (tmp_meta['CellType'] == 'naive_CD8_T_cells')| (tmp_meta['CellType'] == 'effector_CD8_T_cells')]\n",
    "impute_t_bc = set(impute_RP.columns).intersection(keys.loc[impute_t_bc,'RNA'])\n",
    "impute_t_rp = impute_RP[impute_t_bc].max(1)\n",
    "\n",
    "atac_t_rp = atac_rp[impute_t_bc].max(1)\n",
    "\n",
    "real_t_bc = real_matadata.index[(real_matadata['Celltype'] == 'CD4 T') | (real_matadata['Celltype'] == 'CD8 T') | (real_matadata['Celltype'] == 'other T')]\n",
    "# real_t_bc = real_matadata.index[ (real_matadata['Celltype'] == 'CD4 T')]\n",
    "real_t_rp = real_RP[real_t_bc].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81521d92-60b8-4ca0-bc0f-c1008db88bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(impute_t_rp,real_t_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb534623-c558-4dbf-99fa-7f22a776d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(atac_t_rp,real_t_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926438ab-57a7-43e7-975b-d6b66518c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(real_t_rp[bulk_ovlp_target],bulk_t_target_rp[bulk_ovlp_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfbc7c-e865-45b0-b9f2-27a136660ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(impute_t_rp[bulk_ovlp_target],bulk_t_target_rp[bulk_ovlp_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90894e0-39dd-4b52-ac30-2e38f7e28548",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(atac_t_rp[bulk_ovlp_target],bulk_t_target_rp[bulk_ovlp_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce05220-a8c4-4bd7-993c-5daa84295a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mono_bc = tmp_meta.index[(tmp_meta['CellType'] == 'non-classical_monocytes') | (tmp_meta['CellType'] == 'classical_monocytes') | (tmp_meta['CellType'] == 'intermediate_monocytes')]\n",
    "impute_mono_bc = set(impute_RP.columns).intersection(keys.loc[impute_mono_bc,'RNA'])\n",
    "impute_mono_rp = impute_RP[impute_mono_bc].max(1)\n",
    "\n",
    "atac_mono_rp = atac_rp[impute_mono_bc].max(1)\n",
    "\n",
    "real_mono_bc = real_matadata.index[(real_matadata['Celltype'] == 'Mono')]\n",
    "real_mono_rp = real_RP[real_mono_bc].max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94142fa1-19b6-4d93-84cc-367de854897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(impute_mono_rp,real_mono_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd05ca-c5c2-42d0-960c-5bb38d28bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(atac_mono_rp,real_mono_rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713fe2e-52f4-4eb5-8552-33db9afa8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(real_mono_rp[bulk_ovlp_target],bulk_t_target_rp[bulk_ovlp_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffdbf1-cb79-46aa-92de-9f46216035a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame([['Imputed', 'T', 0.7226870110986734], ['Imputed', 'Mono', 0.6901540022681896], \n",
    "                        ['scATAC', 'T', 0.6412991747820043], ['scATAC', 'Mono', 0.6255047796652997], \n",
    "                        ['Bulk', 'T', 0.3856955331547345], ['Bulk', 'Mono', 0.3584068064358755]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1013f2-aed1-4521-8460-6c1d4efe5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.barplot(x=1, y=2, data=data_df, hue=0, palette='Set3', ax=ax)\n",
    "ax.set_xlabel('Cell Type')\n",
    "ax.set_ylabel('RP Correlation with scCUT&Pro')\n",
    "fig.show()\n",
    "fig.savefig('Figures/RP_correlation_imputed_atac_bulk.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37d6bb-b88e-4c27-8362-e633ef308725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target venn overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0317832-b408-4daa-af71-66218a0f0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "out = venn3_unweighted([736, 637, 232, 858, 11, 110, 21], ('scCUT&Pro', 'SCRIP Imputed', 'Bulk'))\n",
    "for x in range(len(out.subset_labels)):\n",
    "    if out.subset_labels[x] is not None:\n",
    "        out.subset_labels[x].set_fontsize(20)\n",
    "fig.show()\n",
    "fig.savefig('Figures/T_target_venn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fae917-0d92-4870-9b75-93cfd9b9fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "out = venn3_unweighted([661, 545, 232, 702, 75, 191, 32], ('scCUT&Pro', 'SCRIP Imputed', 'Bulk'))\n",
    "for x in range(len(out.subset_labels)):\n",
    "    if out.subset_labels[x] is not None:\n",
    "        out.subset_labels[x].set_fontsize(20)\n",
    "fig.show()\n",
    "fig.savefig('Figures/mono_target_venn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100c665-3b58-42e7-a375-e16cf2ee3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/SCRIPT_1114_remove_others/imputation/H3K27ac_T_rp_gene.txt', 'w+') as f:\n",
    "    for i in impute_t_rp[bulk_ovlp_target].sort_values(ascending=False)[0:1000].index.tolist():\n",
    "        f.write(f'{i}\\n')\n",
    "with open('/fs/home/dongxin/Projects/SCRIPT/scATAC/example/histone/SCRIPT_1114_remove_others/imputation/H3K27ac_mono_rp_gene.txt', 'w+') as f:\n",
    "    for i in impute_mono_rp[bulk_ovlp_target].sort_values(ascending=False)[0:1000].index.tolist():\n",
    "        f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff865cc-de5c-4f09-a46f-7aaa0aafd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(real_mono_rp[bulk_ovlp_target].sort_values(ascending=False)[0:1000].index)\n",
    "set2 = set(impute_mono_rp[bulk_ovlp_target].sort_values(ascending=False)[0:1000].index)\n",
    "set3 = set(bulk_mono_target_list[0:1000])\n",
    "\n",
    "venn3([set1, set2, set3], ('scCUT&Pro', 'SCRIP Imputed', 'Bulk'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCRIPT",
   "language": "python",
   "name": "script"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
